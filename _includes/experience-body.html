<!-- ===== ROLE SUMMARY + MENU + PANELS ===== -->
<span id="role-summary" class="role-summary" aria-live="polite">Explore impacts by role.</span>

<div class="role-gallery">
  <nav class="role-menu" aria-label="Choose a role">
    <button class="role-btn active" data-role="analyst" aria-current="page">Data Analyst</button>
    <button class="role-btn" data-role="scientist">Data Scientist</button>
    <button class="role-btn" data-role="engineer">Data Engineer</button>
    <button class="role-btn" data-role="aiml">AI / ML Engineer</button>
    <button class="role-btn" data-role="genai">NLP / Gen AI Specialist</button>
    <button class="role-btn" data-role="businessanalyst">Business Analyst</button>
  </nav>

  <section class="role-slideshows">
    <!-- ========= Analyst ========= -->
    <div class="role-accordion" id="panel-analyst">
      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-analyst-1" id="acc-analyst-1-label">
            UHG — BI Modernization (Tableau → Power BI)
            <span class="acc-meta">Power BI · Tableau · Microsoft 365 · Cost Optimization</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-analyst-1" role="region" aria-labelledby="acc-analyst-1-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I led the migration of reporting from Tableau to Power BI, reducing licensing costs while introducing faster and more flexible reporting prototypes.</p>
            <details><summary>S · Situation</summary><p>UnitedHealth Group was heavily invested in Tableau, but licensing was expensive, and performance optimizations were not yielding significant improvements. End users were dependent on Tableau despite Microsoft 365 already providing Power BI licenses at no extra cost.</p></details>
            <details><summary>T · Task</summary><p>I needed to prove the value of Power BI by quickly creating prototypes that stakeholders would accept. The challenge was to drive cultural change and accelerate transition by moving away from an established tool.</p></details>
            <details><summary>A · Action</summary><p>I created rapid prototypes in Power BI to showcase interactive visuals, improved usability, and integration with existing Microsoft systems. I presented side-by-side comparisons showing both speed improvements and cost savings. I gradually migrated core reports while ensuring consistency of metrics across both platforms during the transition.</p></details>
            <details open><summary>R · Result</summary><p>Licensing costs were reduced by approximately $<span class="kpi" data-target="500">0</span>K annually, since Power BI came bundled with Microsoft 365. Report delivery time improved by ~<span class="kpi" data-target="61">0</span>%, increasing stakeholder adoption. Leadership shifted to Power BI as the primary reporting platform, establishing a long-term reporting strategy.</p>
            </details>
            <p><strong>Stack:</strong> Power BI, SQL Server, DAX, SSIS, Tableau</p>
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-analyst-2" id="acc-analyst-2-label">
            Hyatt BI Apps Performance Analysis
            <span class="acc-meta">SQL · Data Modeling · ETL Loads · Reporting</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-analyst-2" role="region" aria-labelledby="acc-analyst-2-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I improved reporting performance at Hyatt by introducing data archiving and incremental load strategies, which reduced slowness in BI applications and improved end-user adoption.</p>
            <details><summary>S · Situation</summary><p>Hyatt’s BI apps were experiencing slowness caused by large historical datasets. Every report query scanned years of data, making even simple dashboards slow to load. Users were complaining and adoption was dropping.</p></details>
            <details><summary>T · Task</summary><p>I needed to redesign the load process so reports would run faster while keeping historical data accessible. The solution had to balance speed with accuracy and not risk data integrity.</p></details>
            <details><summary>A · Action</summary><p>I proposed and implemented an archiving mechanism for historical data, paired with incremental loading for new data. This allowed queries to focus only on recent periods by default, while archived data could still be accessed if needed. I also restructured indexes to reduce query time further.</p></details>
            <details open><summary>R · Result</summary><p>Report execution time improved by ~<span class="kpi" data-target="58">0</span>%, cutting average load times nearly in half. BI adoption increased as reports became usable in daily operations. Leadership appreciated that the solution preserved access to all historical data without compromising performance.</p>
            </details>
            <p><strong>Stack:</strong> Oracle SQL, PL/SQL, Informatica, OBIEE</p>            
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-analyst-3" id="acc-analyst-3-label">
            UnitedHealth Group – Healthcare Cost Analysis
            <span class="acc-meta">SQL · Regression Analysis · KPI Discovery · Data Visualization</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-analyst-3" role="region" aria-labelledby="acc-analyst-3-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I developed a regression-based cost analysis model for UnitedHealth Group that identified the top drivers of healthcare expenses and introduced new KPIs for leadership review.</p>
            <details><summary>S · Situation</summary><p>Healthcare cost drivers were not accurately defined in many scenarios, leading to generic strategies that did not address high-impact areas. Large datasets were collected, but insights were scattered and inconclusive.</p></details>
            <details><summary>T · Task</summary><p>My responsibility was to analyze healthcare data, identify the most significant factors driving costs, and present actionable KPIs that could be adopted by stakeholders. Many KPIs required extensive validation, ensuring their strength and value for adoption.</p></details>
            <details><summary>A · Action</summary><p>I applied regression analysis on large healthcare datasets to identify key variables affecting costs. The model highlighted age, doctor visits, and pre-existing conditions as the top three drivers. I then designed new KPIs to measure these factors and built clear reports to present them to leadership.</p></details>
            <details open><summary>R · Result</summary><p>The model explained cost variance with ~<span class="kpi" data-target="65">0</span>% accuracy and directly influenced budget decisions. Reporting turnaround time was reduced by <span class="kpi" data-target="55">0</span>%, allowing faster decisions. Leadership adopted the new KPIs, which improved planning accuracy and built trust in data-driven decision making.</p>
            </details>
            <p><strong>Stack:</strong> Power BI, Statistical Analysis, Cluster Analysis</p>            
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-analyst-4" id="acc-analyst-4-label">
            Walgreens Loyalty Data Quality Load Automation
            <span class="acc-meta">SQL · Oracle BI Apps · Data Governance · Automation</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-analyst-4" role="region" aria-labelledby="acc-analyst-4-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I automated a loyalty program data quality process that repeatedly caused extended downtime during month-end reporting. The solution reduced downtime drastically and introduced reliable fallback mechanisms.</p>
            <details><summary>S · Situation</summary><p>Walgreens’ loyalty data load process was prone to repeated failures, requiring multiple reloads. During month-end, these failures caused downtime of nearly seven hours, delaying reports and impacting business users. Time-taking manual steps to fix were part of the standard processes, and system reliability was suffering.</p></details>
            <details><summary>T · Task</summary><p>My task was to improve load reliability, cut downtime, and deliver a rollback option to ensure business continuity. I needed to balance automation with safeguards, since leadership had concerns about unintended disruptions.</p></details>
            <details><summary>A · Action</summary><p>I created an automated data quality detection and reload mechanism with backup and rollback features. The automation checked data integrity before release, reduced dependency on manual reloads, and ensured rapid recovery if needed. Extended working sessions with stakeholders and teams ensured comprehensive clarity on every step of the new process.</p></details>
            <details open><summary>R · Result</summary><p>Downtime was reduced by <span class="kpi" data-target="80">0</span>%, from seven hours to three hours during month-end. Data quality improved by ~<span class="kpi" data-target="67">0</span>%, boosting stakeholder confidence. The rollback feature ensured zero business disruption, and adoption spread across other month-end processes.</p>
            </details>
            <p><strong>Stack:</strong> Oracle SQL, Unix, MDBMS, Hyperion</p>            
          </div>
        </div>
      </article>
      
    </div>

    <!-- ========= Scientist ========= -->
    <div class="role-accordion" id="panel-scientist" hidden>
<article class="acc-item">
  <span class="acc-head">
    <button class="acc-btn" aria-expanded="false" aria-controls="acc-scientist-1" id="acc-scientist-1-label">
      Walgreens — Workforce AI Scheduling and Forecasting
      <span class="acc-meta">Databricks · PySpark · ADF · Time-series</span>
    </button>
  </span>
  <div class="acc-panel" id="acc-scientist-1" role="region" aria-labelledby="acc-scientist-1-label" hidden>
    <div class="acc-body">
      <p><strong>Summary:</strong> Designed and deployed an AI scheduling engine using Python and Gurobi optimization, integrated with time-series forecasting pipelines. The system generates optimized weekly schedules for ~150,000 employees across 8,000+ stores, incorporating availability constraints, store-level demand signals, and fairness rules. Iteratively improved the model for accuracy and reduced manual corrections through incremental learning and feature updates.</p>

      <details><summary>S · Situation</summary>
        <p>Scheduling was previously manual, highly reactive, and error-prone. Store teams spent hours adjusting shifts to align with employee availability, while demand fluctuations created inefficiencies and compliance risks.</p>
      </details>

      <details><summary>T · Task</summary>
        <p>Develop an automated scheduling system that balances employee availability, regulatory rules, and forecasted demand. Reduce the time store leaders spend on manual scheduling, while improving fairness, coverage, and forecast stability.</p>
      </details>

      <details><summary>A · Action</summary>
        <p>Implemented an optimization model in Python leveraging the Gurobi solver to enforce staffing constraints and maximize shift alignment with employee availability. Built Databricks-based PySpark pipelines for data preprocessing and feature engineering (availability parsing, PTO windows, role hierarchies). Integrated time-series forecasts via ADF triggers to dynamically adjust staffing needs. Iteratively enhanced the AI model with incremental improvements—such as day-cap logic, PTO overlap handling, and technician/pharmacist balance—ensuring scalable weekly deployment across 150k employees.</p>
      </details>

      <details open><summary>R · Result</summary>
        <ul>
          <li><span class="kpi" data-target="30">0</span>% reduction in manual intervention</li>
          <li>Automated weekly scheduling for 150,000+ employees, reducing store-level manual effort by thousands of hours</li>
          <li>Improved schedule fairness and availability matching, lowering late shift corrections</li>
          <li>Delivered scalable AI-driven scheduling framework now used enterprise-wide</li>
        </ul>
      </details>

      <p><strong>Stack:</strong> Python, Gurobi, PySpark, Databricks, ADF, ADLS</p>
    </div>
  </div>
</article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-scientist-2" id="acc-scientist-2-label">
            UnitedHealth Group – Healthcare Cost Regression Model
            <span class="acc-meta">Python · SQL · Regression Analysis · Healthcare Analytics</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-scientist-2" role="region" aria-labelledby="acc-scientist-2-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I built a regression model to identify the strongest predictors of healthcare costs, providing stakeholders with clear KPIs and actionable insights that improved decision-making around cost management.</p>
            <details><summary>S · Situation</summary><p>UnitedHealth Group faced rising healthcare costs without clear visibility into the primary drivers. Leadership relied on fragmented reporting, which made it difficult to prioritize interventions. Existing KPIs were broad and lacked specificity.</p></details>
            <details><summary>T · Task</summary><p>I needed to create a data science solution that could explain cost variance across patients, identify the most significant contributing factors, and suggest new KPIs for monitoring. This required careful statistical validation to gain executive trust.</p></details>
            <details><summary>A · Action</summary><p>I developed a regression model using large patient datasets. The analysis revealed interesting and actionable insights on factors that accounted for the majority of cost variance. I created new KPIs around these drivers and visualized the findings in clear, stakeholder-friendly reports. I presented results directly to leadership, bypassing delays in KPI approvals.</p></details>
            <details open><summary>R · Result</summary><p>The model explained ~<span class="kpi" data-target="66">0</span>% of cost variance and reduced reporting complexity by <span class="kpi" data-target="57">0</span>%. Leadership adopted the new KPIs, which improved cost forecasting accuracy by over <span class="kpi" data-target="60">0</span>%. My work influenced key budget allocation decisions and helped establish predictive modeling as part of UnitedHealth’s analytics strategy.</p>
            </details>
            <p><strong>Stack:</strong> Python, SQL Server, SSIS, Tableau</p>
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-scientist-3" id="acc-scientist-3-label">
            Walgreens – Predictive Alerts & Insights in BI Apps
            <span class="acc-meta">Python · Time Series Forecasting · SQL · Statistical Modeling</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-scientist-3" role="region" aria-labelledby="acc-scientist-3-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I designed and deployed a predictive alert system within Walgreens BI applications to forecast operational issues, reducing unexpected disruptions and improving response times.</p>
            <details><summary>S · Situation</summary><p>Walgreens experienced recurring issues in BI application data loads. Failures were usually detected only after problems escalated, resulting in delayed reporting and user frustration. The lack of proactive detection created inefficiencies across multiple business units.</p></details>
            <details><summary>T · Task</summary><p>I was tasked with improving the reliability of BI applications. Initially, the scope was limited to fixing load issues, but I recognized the opportunity to introduce predictive analytics to anticipate failures before they caused downstream problems.</p></details>
            <details><summary>A · Action</summary><p>I applied time-series forecasting models to historical load data to identify recurring failure patterns. I created a predictive alert mechanism that flagged likely failures and provided insights to system administrators. The solution was embedded directly into existing BI apps, ensuring seamless adoption without requiring additional platforms.</p></details>
            <details open><summary>R · Result</summary><p>Prediction accuracy reached ~<span class="kpi" data-target="62">0</span>%, allowing teams to act on alerts proactively. Report delays were reduced by <span class="kpi" data-target="55">0</span>%, and end-user satisfaction increased significantly. The system became a model for predictive monitoring in other Walgreens applications.</p>
            </details>
            <p><strong>Stack:</strong> Statistical Analysis, Python, PL/SQL, Unix</p>
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-scientist-4" id="acc-scientist-4-label">
            Experian – Sales Insight Regression for EMEA & APAC
            <span class="acc-meta">Python · Regression Analysis · SQL · Market Analytics</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-scientist-4" role="region" aria-labelledby="acc-scientist-4-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I implemented regression models within Experian’s Sales Insight platform to analyze customer behavior across EMEA and APAC regions, providing leadership with more accurate forecasting and improved customer segmentation.</p>
            <details><summary>S · Situation</summary><p>Experian needed to improve sales forecasting and customer analysis across EMEA and APAC. Existing reporting tools were descriptive but failed to uncover deep relationships between customer factors and revenue outcomes.</p></details>
            <details><summary>T · Task</summary><p>My task was to apply advanced analytics to customer data, identify meaningful drivers of sales, and generate insights that could be used to improve regional sales strategies.</p></details>
            <details><summary>A · Action</summary><p>I built regression models that linked customer demographics, engagement frequency, and product mix to revenue outcomes. I collaborated with business stakeholders in both regions to ensure the models reflected local realities. The results were translated into actionable reports with prototypes of improved KPIs.</p></details>
            <details open><summary>R · Result</summary><p>The regression models improved forecast accuracy by ~<span class="kpi" data-target="60">0</span>% compared to prior methods. Regional managers used the insights to refine customer targeting strategies, which led to an estimated <span class="kpi" data-target="55">0</span>% improvement in campaign ROI. Leadership adopted the regression framework as a standard part of sales insight reporting.</p>
            </details>
            <p><strong>Stack:</strong> Python, Informatica, PL/SQL, Statistical Analysis</p>
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-scientist-5" id="acc-scientist-5-label">
            Bombardier – Databricks KPI Creation via Analytics
            <span class="acc-meta">Databricks · Python · SQL · KPI Development · Data Governance</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-scientist-5" role="region" aria-labelledby="acc-scientist-5-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I leveraged Databricks to design actionable KPIs for Bombardier after analyzing stakeholder needs and aligning reporting with business OKRs, significantly improving governance and decision-making.</p>
            <details><summary>S · Situation</summary><p>Bombardier’s teams needed consistent KPIs and struggled with fragmented governance across data sources. Stakeholders had different interpretations of the same metrics, leading to confusion and inefficient decision-making.</p></details>
            <details><summary>T · Task</summary><p>I was tasked with creating standardized KPIs that aligned with organizational OKRs and addressed the pain points of each team. I needed to balance diverse stakeholder requirements while ensuring governance compliance.</p></details>
            <details><summary>A · Action</summary><p>I met with stakeholders across teams to understand reporting needs and existing gaps. Using Databricks, I processed large volumes of operational and financial data to derive consistent KPIs. I validated these with stakeholders through prototypes and refined them iteratively to ensure adoption.</p></details>
            <details open><summary>R · Result</summary><p>Adoption of new KPIs improved reporting accuracy by ~<span class="kpi" data-target="59">0</span>%. Teams reduced metric-related disputes by over <span class="kpi" data-target="65">0</span>%, improving trust in analytics. Leadership highlighted the initiative as a cornerstone for data governance maturity.</p>
            </details>
            <p><strong>Stack:</strong> Python, Databricks, SQL, Data Governance</p>
          </div>
        </div>
      </article>
      
    </div>

    <!-- ========= Engineer ========= -->
    <div class="role-accordion" id="panel-engineer" hidden>
      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-engineer-1" id="acc-engineer-1-label">
            Walgreens – Out-of-the-Box BI Apps Load Tuning
            <span class="acc-meta">PL/SQL · Oracle BI Apps · Performance Tuning · ETL</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-engineer-1" role="region" aria-labelledby="acc-engineer-1-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I optimized Walgreens’ BI Apps load process by analyzing dependency chains and creating parallel execution strategies. This improved overall load performance and helped establish new KPIs for system monitoring.</p>
            <details><summary>S · Situation</summary><p>Walgreens’ BI Apps suffered from long-running Out-of-the-Box loads that delayed reporting. The business required timely reporting for executive dashboards, but load inefficiencies caused frequent bottlenecks. There were concerns in modifying vendor-delivered jobs, fearing compliance risks.</p></details>
            <details><summary>T · Task</summary><p>I needed to optimize system performance while respecting Out-of-the-Box restrictions. The goal was to speed up data availability without compromising vendor support or introducing system instability.</p></details>
            <details><summary>A · Action</summary><p>I performed dependency analysis on tables and fact-dimension relationships. I restructured jobs into parallel execution groups, ensuring loads were ordered logically but without unnecessary serialization. I also introduced KPIs to measure system performance, which allowed me to demonstrate consistent improvements.</p></details>
            <details open><summary>R · Result</summary><p>Data load completion time was reduced by ~<span class="kpi" data-target="59">0</span>%, making critical dashboards available hours earlier. Reporting accuracy improved by ~<span class="kpi" data-target="54">0</span>% as dependencies were better synchronized. Leadership adopted performance KPIs as part of the monitoring process, enabling sustainable improvements.</p>
            </details>
            <p><strong>Stack:</strong> Python, PL/SQL, Oracle Data Integrator, Oracle BI Apps</p>            
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-engineer-2" id="acc-engineer-2-label">
            Experian – DMT (Data Migration Tool) Performance Tuning
            <span class="acc-meta">PL/SQL · ETL Optimization · Data Quality · Automation</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-engineer-2" role="region" aria-labelledby="acc-engineer-2-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I optimized Experian’s DMT to process large volumes of data faster, delivering significant improvements in migration efficiency for senior leadership teams.</p>
            <details><summary>S · Situation</summary><p>Experian’s DMT struggled to process large daily loads, creating bottlenecks for cross-regional data migration. Leadership needed timely results to meet SLAs, but the tool’s performance was inconsistent and often caused delays.</p></details>
            <details><summary>T · Task</summary><p>I was tasked with improving throughput and efficiency of DMT jobs without sacrificing data quality checks. The solution had to demonstrate tangible improvements in both processing speed and reliability.</p></details>
            <details><summary>A · Action</summary><p>I tuned queries, streamlined data validation scripts, and implemented incremental batch execution instead of full reprocessing. I also automated validation checks to prevent manual bottlenecks and ensure quality at scale.</p></details>
            <details open><summary>R · Result</summary><p>Processing speed improved by ~<span class="kpi" data-target="66">0</span>%, cutting migration times significantly. Reliability increased by ~<span class="kpi" data-target="58">0</span>%, ensuring more consistent SLA compliance. Leadership recognized the optimization as a high-value contribution to EMEA/APAC reporting efficiency.</p>
            </details>
            <p><strong>Stack:</strong> PL/SQL, Unix, Windows PowerShell</p>
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-engineer-3" id="acc-engineer-3-label">
            Walgreens – DRM Server Implementation
            <span class="acc-meta">Oracle EPM · Data Governance · Systems Integration</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-engineer-3" role="region" aria-labelledby="acc-engineer-3-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I implemented a Oracle Hyperion Data Relationship Management (DRM) server for Walgreens in just two weeks, enabling critical master data management and data governance capabilities during a business-sensitive period.</p>
            <details><summary>S · Situation</summary><p>Walgreens urgently needed a test DRM environment to validate critical reporting changes. Leadership initially considered manual workarounds due to the tight timeline and perceived complexity of setup.</p></details>
            <details><summary>T · Task</summary><p>I had to deliver a fully functional DRM test environment quickly, with minimal disruption, and without relying on manual processes.</p></details>
            <details><summary>A · Action</summary><p>I leveraged my systems knowledge to configure, test, and validate a new DRM server instance. I automated portions of the setup with Windows scripting to save time. I coordinated with infrastructure teams to streamline approvals and deployment.</p></details>
            <details open><summary>R · Result</summary><p>The server was deployed in <span class="kpi" data-target="14">0</span> days, ahead of the critical deadline. Testing downtime risk was reduced by ~<span class="kpi" data-target="62">0</span>% compared to manual alternatives. This success built trust in automation-first approaches for infrastructure delivery ultimately helping in stronger master data governance.</p>
            </details>
            <p><strong>Stack:</strong> Oracle EPM, Hyperion, Data Governance, Windows PowerShell</p>            
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-engineer-4" id="acc-engineer-4-label">
            Toyota Financial Services – Data Load Strategy
            <span class="acc-meta">ETL · Data Warehouse · PL/SQL · Process Optimization</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-engineer-4" role="region" aria-labelledby="acc-engineer-4-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I redesigned Toyota’s data load process by opting for full re-extractions instead of incremental loads to prevent downstream data loss.</p>
            <details><summary>S · Situation</summary><p>Toyota Financial Services faced frequent reporting discrepancies caused by incremental data loads missing updates. Downstream systems were impacted, and leadership was concerned about data reliability.</p></details>
            <details><summary>T · Task</summary><p>I was responsible for ensuring that downstream systems received accurate and complete data, even if this required rethinking the traditional incremental load strategy.</p></details>
            <details><summary>A · Action</summary><p>Drawing from past experience, I proposed full data re-extractions, ensuring complete synchronization across systems. I optimized the process to minimize runtime impacts, balancing completeness with performance.</p></details>
            <details open><summary>R · Result</summary><p>Data reliability improved by ~<span class="kpi" data-target="65">0</span>%, with downstream discrepancies nearly eliminated. Although processing times increased slightly, stakeholder trust in reporting accuracy improved dramatically. This trade-off was accepted as the best solution.</p>
            </details>
            <p><strong>Stack:</strong> PL/SQL, Informatica PowerCenter, Unix, DAC</p>            
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-engineer-5" id="acc-engineer-5-label">
            Experian – SOOSA C 2.1 Daily Load Optimization
            <span class="acc-meta">PL/SQL · ETL · Process Automation · Data Warehousing</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-engineer-5" role="region" aria-labelledby="acc-engineer-5-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I optimized Experian’s SOOSA C 2.1 daily load, reducing downtime by 70% through new process design and automation.</p>
            <details><summary>S · Situation</summary><p>Experian’s daily load jobs were prone to failures, consuming excessive time and delaying critical reports across global regions. Leadership was pressuring the team to improve reliability quickly.</p></details>
            <details><summary>T · Task</summary><p>I was tasked with redesigning the process to reduce downtime and improve load performance, ensuring faster delivery of daily reports.</p></details>
            <details><summary>A · Action</summary><p>I created optimized SQL procedures, parallelized portions of the ETL process, and automated restart checkpoints. I built monitoring scripts to flag and restart failed jobs without manual intervention.</p></details>
            <details open><summary>R · Result</summary><p>Downtime was reduced by <span class="kpi" data-target="70">0</span>%, and daily reporting timelines improved by ~<span class="kpi" data-target="60">0</span>%. Stakeholder confidence increased, and the optimized framework became the new standard for daily data processing.</p>
            </details>
            <p><strong>Stack:</strong> PL/SQL, Informatica PowerCenter, Unix, DAC</p>              
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-engineer-6" id="acc-engineer-6-label">
            Walgreens – RiteAid Data Warehouse Modeling
            <span class="acc-meta">PL/SQL · Data Modeling · Fact-Dimension Design · Data Governance</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-engineer-6" role="region" aria-labelledby="acc-engineer-6-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I created a new data warehouse model for RiteAid integration within Walgreens, supporting balance, journal, and account reporting with proper governance.</p>
            <details><summary>S · Situation</summary><p>Walgreens needed to integrate RiteAid’s reporting structure into its own warehouse. The existing models did not align with new governance requirements, leading to inconsistent reporting.</p></details>
            <details><summary>T · Task</summary><p>My goal was to design a warehouse model that incorporated RiteAid’s data while maintaining consistent governance and reporting performance.</p></details>
            <details><summary>A · Action</summary><p>I designed fact and dimension models covering balances, journals, and accounts. I worked with governance teams to ensure compliance and created structures that minimized redundancy. I tested models against existing reports to validate correctness.</p></details>
            <details open><summary>R · Result</summary><p>Integration accuracy improved by ~<span class="kpi" data-target="61">0</span>%, and reporting consistency across Walgreens and RiteAid data was achieved. Performance improved by ~<span class="kpi" data-target="55">0</span>% as models were streamlined for query efficiency.</p>
            </details>
            <p><strong>Stack:</strong> PL/SQL, Oracle BI Apps, Unix, Shell Scripting</p>              
          </div>
        </div>
      </article>      
    </div>

    <!-- ========= AI/ML ========= -->
    <div class="role-accordion" id="panel-aiml" hidden>
    
      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-aiml-1" id="acc-aiml-1-label">
            Walgreens – Predictive Alerts & Insights in BI Apps
            <span class="acc-meta">PL/SQL · Python · Time-Series Forecasting · BI Integration</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-aiml-1" role="region" aria-labelledby="acc-aiml-1-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I transformed a recurring load issue into a predictive analytics opportunity, building forecasting models that enabled proactive alerts and actionable insights in Walgreens’ BI applications.</p>
            <details><summary>S · Situation</summary><p>Walgreens BI teams faced frequent reporting delays due to data load failures. Stakeholders only requested fixes to stabilize the load, but this reactive approach left the business exposed to recurring risks. There was skepticism in predictive solutions because of concerns about model reliability.</p></details>
            <details><summary>T · Task</summary><p>I had to stabilize the immediate reporting issue while exploring predictive models that could forecast both failures and business trends. The challenge was to prove value quickly and minimize perceived risk.</p></details>
            <details><summary>A · Action</summary><p>I developed time-series forecasting models using Python and SQL to detect anomalies and predict future failures. I integrated predictive alerts directly into BI dashboards, enabling business users to see both risks and forward-looking metrics. I also iteratively refined models to reduce false positives, gaining confidence from end users.</p></details>
            <details open><summary>R · Result</summary><p>The solution reduced reporting disruptions by ~<span class="kpi" data-target="66">0</span>%, preventing multiple critical outages. Business teams began using predictive dashboards to anticipate issues and plan actions. This success demonstrated that predictive analytics could be embedded directly in operational BI systems.</p>
            </details>
            <p><strong>Stack:</strong> Statistical Analysis, PL/SQL, Python, Unix</p>              
          </div>
        </div>
      </article>    

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-aiml-2" id="acc-aiml-2-label">
            Bombardier – Databricks KPI & OKR Development
            <span class="acc-meta">Databricks · Machine Learning · KPI Definition · Data Governance</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-aiml-2" role="region" aria-labelledby="acc-aiml-2-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I created machine learning–driven KPIs and OKRs for Bombardier, aligning data governance with team-level business goals.</p>
            <details><summary>S · Situation</summary><p>Bombardier needed standardized KPIs across departments, without it leadership had difficulty measuring progress. Each team tracked metrics differently, resulting in fragmented reporting and misaligned goals.</p></details>
            <details><summary>T · Task</summary><p>I was responsible for analyzing the reporting landscape, consulting with stakeholders, and defining actionable KPIs supported by ML-driven insights.</p></details>
            <details><summary>A · Action</summary><p>I interviewed stakeholders across teams to understand their pain points and goals. Using Databricks, I combined data sources and built ML-based models to highlight the most impactful metrics. I then proposed new KPIs and created a framework to align them with company-wide OKRs.</p></details>
            <details open><summary>R · Result</summary><p>KPI adoption increased by ~<span class="kpi" data-target="64">0</span>% across teams, creating a unified reporting strategy. Leadership had clearer visibility into business performance, and governance became data-driven. The initiative positioned ML-driven KPI frameworks as the standard for analytics maturity at Bombardier.</p>
            </details>
            <p><strong>Stack:</strong> Databricks, Python, Statistical Analysis</p>              
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-aiml-3" id="acc-aiml-3-label">
            Galderma – Automated Reporting with ML Insights
            <span class="acc-meta">Databricks · Power BI · ML Models · Reporting Automation</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-aiml-3" role="region" aria-labelledby="acc-aiml-3-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I replaced manual Excel-based reporting at Galderma with automated pipelines and machine learning models that generated actionable insights.</p>
            <details><summary>S · Situation</summary><p>Galderma’s reporting relied heavily on manual Excel work, which was slow, error-prone, and not scalable. Users spent hours preparing reports instead of analyzing results. Leadership sought an automation-first solution but needed in-house ML expertise.</p></details>
            <details><summary>T · Task</summary><p>I needed to automate the reporting process, integrate ML insights, and ensure reports were delivered faster and with higher accuracy.</p></details>
            <details><summary>A · Action</summary><p>I built Databricks pipelines to ingest and preprocess raw data automatically. I applied ML models to generate predictive KPIs such as churn risk and sales forecasts. I connected the outputs to Power BI dashboards, ensuring stakeholders could easily consume the insights.</p></details>
            <details open><summary>R · Result</summary><p>Manual reporting effort was reduced by ~<span class="kpi" data-target="70">0</span>%, saving dozens of hours each week. Forecasting accuracy improved by ~<span class="kpi" data-target="61">0</span>%, giving leadership actionable insights. The automation freed up analysts to focus on strategy rather than manual tasks.</p>
            </details>
            <p><strong>Stack:</strong> Databricks, Python, Statistical Analysis</p>              
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-aiml-4" id="acc-aiml-4-label">
            Walgreens – Field Transformation Program Analytics
            <span class="acc-meta">ML Models · Data Governance · Predictive Insights · Integration</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-aiml-4" role="region" aria-labelledby="acc-aiml-4-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I applied machine learning within Walgreens’ Field Transformation Program to balance upstream and downstream system changes, providing predictive insights that minimized risk.</p>
            <details><summary>S · Situation</summary><p>Walgreens was undergoing a major field transformation, with tightly integrated upstream and downstream system changes. These dependencies created risks of cascading failures if not managed proactively.</p></details>
            <details><summary>T · Task</summary><p>My task was to provide predictive insights to anticipate where risks could occur, ensuring system stability during transformation.</p></details>
            <details><summary>A · Action</summary><p>I analyzed transformation data and built ML models to simulate impacts of system changes. By predicting high-risk scenarios, I advised teams on preventive actions. I collaborated with both governance and analytics teams to validate models against real-world outcomes.</p></details>
            <details open><summary>R · Result</summary><p>Transformation risks were reduced by ~<span class="kpi" data-target="60">0</span>%, with fewer unplanned outages during rollout. Predictive insights improved coordination across teams and accelerated program delivery timelines by ~<span class="kpi" data-target="55">0</span>%. The success showcased the value of ML in system transformation projects.</p>
            </details>
            <p><strong>Stack:</strong> Statistical Analysis, PL/SQL, Data Governance</p>              
          </div>
        </div>
      </article>      
    </div>
    
    <!-- ========= GenAI ========= -->
    <div class="role-accordion" id="panel-genai" hidden>
    
      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-genai-1" id="acc-genai-1-label">
            UnitedHealth Group – KPI Generation & Report Prototypes
            <span class="acc-meta">Python · NLP · KPI Automation · Data Visualization</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-genai-1" role="region" aria-labelledby="acc-genai-1-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I proposed and delivered new KPIs for UnitedHealth Group by analyzing stakeholder requests and converting textual requirements into structured, data-driven metrics.</p>
            <details><summary>S · Situation</summary><p>Product owners often described their needs in natural language, requesting “better insights” without clear definitions. Traditional BI processes failed to capture these requirements efficiently, leading to long delays in reporting improvements.</p></details>
            <details><summary>T · Task</summary><p>I had to interpret ambiguous requirements, define precise KPIs, and build rapid prototypes that aligned with leadership’s intent, even without formal approvals.</p></details>
            <details><summary>A · Action</summary><p>I used text-mining and classification techniques to parse stakeholder feedback, extracting common themes. I mapped those into quantifiable KPIs such as “member engagement by visit type” and “condition-specific cost ratios.” I then rapidly built prototypes in Python and BI tools to visualize the new KPIs.</p></details>
            <details open><summary>R · Result</summary><p>Stakeholder satisfaction improved by ~<span class="kpi" data-target="62">0</span>%, as prototypes directly matched their intent and reduced adhoc data request counts. KPI adoption increased across multiple product lines, reducing report development cycles by ~<span class="kpi" data-target="57">0</span>%. The project demonstrated how NLP-driven requirement analysis could accelerate insight creation.</p>
            </details>
            <p><strong>Stack:</strong> Python, NLP, Statistical Analysis, Power BI</p>              
          </div>
        </div>
      </article>   

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-genai-2" id="acc-genai-2-label">
            Galderma – Stakeholder KPI Creation through Data Narratives
            <span class="acc-meta">Databricks · Power BI · Text-to-Metric Translation · Data Storytelling</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-genai-2" role="region" aria-labelledby="acc-genai-2-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I collaborated with Galderma stakeholders to translate raw narratives about business challenges into fresh KPIs, enabling more actionable reporting.</p>
            <details><summary>S · Situation</summary><p>Stakeholders described problems in narrative form, such as “our reporting doesn’t reflect treatment-level outcomes.” These narratives rarely translated into clear data fields, leaving gaps in reporting.</p></details>
            <details><summary>T · Task</summary><p>My job was to bridge the gap between unstructured stakeholder input and structured KPI design, while ensuring dashboards reflected real-world business meaning.</p></details>
            <details><summary>A · Action</summary><p>I applied text-based clustering to stakeholder inputs to group common pain points. I then transformed those clusters into structured KPIs, validated by subject matter experts. Using Databricks pipelines, I automated data collection for these KPIs and built Power BI dashboards to present them.</p></details>
            <details open><summary>R · Result</summary><p>KPI relevance improved by ~<span class="kpi" data-target="65">0</span>%, ensuring reports answered real stakeholder concerns. Dashboard usage increased by ~<span class="kpi" data-target="52">0</span>% as leaders recognized their input reflected in metrics. This effort strengthened trust in data-driven storytelling across the organization.</p>
            </details>
            <p><strong>Stack:</strong> Databricks, Python, Power BI</p>              
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-genai-3" id="acc-genai-3-label">
            Hyatt – Text-to-KPI Performance Enhancement
            <span class="acc-meta">SQL · Text Mining · Prototype Dashboards · Data Analysis</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-genai-3" role="region" aria-labelledby="acc-genai-3-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I introduced new KPIs at Hyatt by mining performance review notes and transforming qualitative observations into structured metrics.</p>
            <details><summary>S · Situation</summary><p>Hyatt’s reporting relied on traditional KPIs, but managers often documented observations in free-text fields that were never analyzed. These unstructured notes contained valuable insights but went unused.</p></details>
            <details><summary>T · Task</summary><p>I needed to extract themes from text data and design KPIs that reflected operational issues, improving the richness of reporting dashboards.</p></details>
            <details><summary>A · Action</summary><p>I performed text mining on review notes to identify recurring topics, such as “check-in delays” and “room readiness.” I translated these into structured KPIs, then built prototype dashboards to visualize the new metrics. I validated the KPIs with managers to ensure they aligned with observed challenges.</p></details>
            <details open><summary>R · Result</summary><p>Reporting coverage expanded by ~<span class="kpi" data-target="60">0</span>%, incorporating previously ignored operational signals. Dashboard refresh cycles were ~<span class="kpi" data-target="55">0</span>% faster since structured KPIs simplified aggregation. Leadership recognized the dashboards as more actionable and holistic.</p>
            </details>
            <p><strong>Stack:</strong> Python, Data Mining, Dashboards</p>              
          </div>
        </div>
      </article>

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-genai-4" id="acc-genai-4-label">
            Walgreens – Automated Data Quality Narratives
            <span class="acc-meta">Python · NLP · Data Quality · Automation</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-genai-4" role="region" aria-labelledby="acc-genai-4-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I automated data quality reporting at Walgreens by generating textual narratives alongside dashboards, helping leadership interpret issues faster.</p>
            <details><summary>S · Situation</summary><p>Data quality reports were highly technical, full of metrics but lacking context. Business stakeholders struggled to interpret whether a flagged issue was critical or negligible. This delayed decision-making and reduced trust in reporting.</p></details>
            <details><summary>T · Task</summary><p>My goal was to generate plain-language narratives that summarized data quality checks, highlighting only the most important issues and suggesting next actions.</p></details>
            <details><summary>A · Action</summary><p>I built an NLP-driven module that generated short narratives for each data quality check, e.g., “Loyalty transactions dropped by 15% this week, likely due to system downtime.” I integrated these summaries into BI dashboards so that executives could read them alongside charts.</p></details>
            <details open><summary>R · Result</summary><p>Stakeholder comprehension improved by ~<span class="kpi" data-target="67">0</span>%, measured through feedback surveys. Decision-making latency decreased by ~<span class="kpi" data-target="56">0</span>%, as executives no longer had to consult technical teams for interpretation. The feature became a template for narrative reporting in other departments.</p>
            </details>
            <p><strong>Stack:</strong> Python, NLP, Data Visualization, Power BI</p>              
          </div>
        </div>
      </article>      
    </div>
    
    
    <!-- ========= Business Analyst ========= -->
    <div class="role-accordion" id="panel-businessanalyst" hidden>
    
      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-businessanalyst-1" id="acc-businessanalyst-1-label">
            Walgreens – FAH Load Quality Detection & Stakeholder Alignment
            <span class="acc-meta">SQL · Oracle BI Apps · Data Governance · Stakeholder Management</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-businessanalyst-1" role="region" aria-labelledby="acc-businessanalyst-1-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I resolved data quality challenges in Walgreens’ Financial Accounting Hub (FAH) by balancing technical optimization with stakeholder concerns, building trust while delivering automation.</p>
            <details><summary>S · Situation</summary><p>Walgreens’ FAH Out-of-the-Box load produced reporting discrepancies. Modifications to vendor-delivered jobs were risky, leading to compliance issues. Business teams needed accurate reports but were impacted by delays and data quality discrepancies.</p></details>
            <details><summary>T · Task</summary><p>I was tasked with improving reporting accuracy while addressing compliance risks. I needed to deliver improvements without impacting user experience or violating vendor agreements.</p></details>
            <details><summary>A · Action</summary><p>I designed a complementary load process that operated in parallel, validating data quality without modifying the original vendor jobs. I framed the solution as a non-intrusive safeguard, not a replacement. I presented prototypes to stakeholders and positioned the project as risk-free, ensuring their buy-in.</p></details>
            <details open><summary>R · Result</summary><p>Reporting accuracy improved by ~<span class="kpi" data-target="63">0</span>%. Month-end report preparation time dropped from six hours to less than two. Stakeholder adoption was strong, as the compromise respected vendor constraints while still achieving automation goals.</p>
            </details>
            <p><strong>Stack:</strong> PL/SQL, Oracle Data Integrator, Oracle BI Apps</p>              
          </div>
        </div>
      </article> 

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-businessanalyst-2" id="acc-businessanalyst-2-label">
            UnitedHealth Group – Power BI Migration Advocacy
            <span class="acc-meta">Power BI · Tableau · Microsoft 365 · Cost Strategy</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-businessanalyst-2" role="region" aria-labelledby="acc-businessanalyst-2-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I led a major reporting transformation at UHG by advocating for Power BI over Tableau, overcoming resistance through prototypes and financial justification.</p>
            <details><summary>S · Situation</summary><p>Stakeholders were committed to Tableau despite its high licensing costs and limited optimization potential. Power BI was already available through Microsoft 365 licenses but sat unused. Leadership feared disruption from a full migration.</p></details>
            <details><summary>T · Task</summary><p>I needed to prove that Power BI was a viable replacement for Tableau, both technically and financially. My role was to manage stakeholder concerns, secure buy-in, and present a vision for the migration.</p></details>
            <details><summary>A · Action</summary><p>I created rapid Power BI prototypes showing side-by-side comparisons with Tableau. I demonstrated improved usability, faster refresh times, and seamless integration with existing systems. I emphasized cost savings of roughly $15 per user per month, multiplied across thousands of licenses.</p></details>
            <details open><summary>R · Result</summary><p>Leadership approved the migration. Licensing costs dropped by ~<span class="kpi" data-target="65">0</span>%, saving nearly $<span class="kpi" data-target="500">0</span>K annually. Stakeholder adoption grew quickly, with report delivery time improving by ~<span class="kpi" data-target="61">0</span>%. I successfully shifted organizational culture toward Power BI as the strategic reporting platform.</p>
            </details>
            <p><strong>Stack:</strong> Power BI, Tableau, SQL Server, Python</p>              
          </div>
        </div>
      </article> 

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-businessanalyst-3" id="acc-businessanalyst-3-label">
            Walgreens – MDBMS Cube Decision Trade-Offs
            <span class="acc-meta">BI Apps · Data Warehousing · Stakeholder Management</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-businessanalyst-3" role="region" aria-labelledby="acc-businessanalyst-3-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I guided Walgreens’ reporting teams through a trade-off decision, balancing optimal technical solutions with business timelines and stakeholder priorities.</p>
            <details><summary>S · Situation</summary><p>Walgreens requested a new cube design for MDBMS reporting. While the optimal solution was to create a fresh cube, leadership insisted on modifying existing cubes to save time. This created risk of slowness as cube size expanded.</p></details>
            <details><summary>T · Task</summary><p>My responsibility was to ensure stakeholders understood the trade-offs and commit to a solution aligned with both technical feasibility and business urgency.</p></details>
            <details><summary>A · Action</summary><p>I presented side-by-side comparisons of cube strategies, including estimated performance impacts. I explained that modifying existing cubes would risk slowness but respected the business timeline. I gained agreement to proceed with modifications while documenting performance risks.</p></details>
            <details open><summary>R · Result</summary><p>Stakeholders adopted the modified cube solution. Performance impact was partially mitigated by query optimization, reducing slowness by ~<span class="kpi" data-target="55">0</span>%. Most importantly, business timelines were met without conflict, and leadership trusted me as a balanced advisor.</p>
            </details>
            <p><strong>Stack:</strong> Oracle BI Apps, PL/SQL, Hyperion</p>              
          </div>
        </div>
      </article> 

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-businessanalyst-4" id="acc-businessanalyst-4-label">
            Bombardier – Cross-Team KPI Governance Alignment
            <span class="acc-meta">Databricks · KPI Framework · Stakeholder Collaboration</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-businessanalyst-4" role="region" aria-labelledby="acc-businessanalyst-4-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I drove stakeholder alignment at Bombardier by consolidating fragmented reporting practices into a unified KPI governance framework.</p>
            <details><summary>S · Situation</summary><p>Teams across Bombardier tracked metrics differently, leading to misaligned goals and conflicting reporting outputs. Leadership needed a common framework to evaluate performance but struggled to gain consensus.</p></details>
            <details><summary>T · Task</summary><p>My task was to bridge team silos, identify common ground, and define KPIs that could satisfy multiple departments.</p></details>
            <details><summary>A · Action</summary><p>I organized workshops with stakeholders to surface pain points and goals. I mapped common themes and proposed unified KPIs that addressed multiple needs. Using Databricks, I built data pipelines that supported these KPIs, ensuring technical scalability alongside governance.</p></details>
            <details open><summary>R · Result</summary><p>Consensus adoption of the unified KPIs reached ~<span class="kpi" data-target="68">0</span>% across departments. Reporting conflicts decreased significantly, and leadership gained consistent visibility across teams. The project improved trust and created a governance template for future KPI initiatives.</p>
            </details>
            <p><strong>Stack:</strong> Databricks, Python, Data Mining</p>              
          </div>
        </div>
      </article> 

      <article class="acc-item">
        <span class="acc-head">
          <button class="acc-btn" aria-expanded="false" aria-controls="acc-businessanalyst-5" id="acc-businessanalyst-5-label">
            Walgreens – SLA Issue Resolution & Trust-Building
            <span class="acc-meta">ETL · BI Apps · Cross-Team Collaboration · Incident Management</span>
          </button>
        </span>
        <div class="acc-panel" id="acc-businessanalyst-5" role="region" aria-labelledby="acc-businessanalyst-5-label" hidden>
          <div class="acc-body">
            <p><strong>Summary:</strong> I resolved a persistent Subledger Accounting (SLA) reporting failure at Walgreens by collaborating directly with technical teams and rebuilding trust through hands-on problem-solving.</p>
            <details><summary>S · Situation</summary><p>A special character handling issue caused Walgreens’ SLA reporting system to fail intermittently. Teams defaulted to manual extraction as a workaround, and a permanent fix was long overdue. Business users were impacted, and trust in IT systems were declining.</p></details>
            <details><summary>T · Task</summary><p>I needed to own the issue, identify the root cause, and build a permanent fix that stakeholders could trust. The solution had to balance vendor restrictions with practical reliability.</p></details>
            <details><summary>A · Action</summary><p>I engaged multiple teams to trace the failure source, analyzed data lineage, and designed a custom load process to handle problematic cases. Since vendor jobs could not be altered, I created an external complementary process. I worked alongside technical and also infrastructure teams directly, to ensure streamlined implementation.</p></details>
            <details open><summary>R · Result</summary><p>System stability improved by ~<span class="kpi" data-target="66">0</span>%, with manual extractions eliminated. SLA compliance improved across multiple reporting cycles. Most importantly, stakeholder trust was rebuilt as they saw me personally take ownership of resolving the issue.</p>
            </details>
            <p><strong>Stack:</strong> PL/SQL, Oracle Data Integrator, Oracle BI Apps</p>              
          </div>
        </div>
      </article>       
    </div>
      
  </section>
</div>

<!-- ===== EXPERIENCE FLOW (ARROW UNDERLAY) ===== -->
<section class="flow experience-flow" id="experience-flow">
  <svg class="flow-svg" id="flow-svg" aria-hidden="true"></svg>
  <div class="flow-grid" id="flow-grid">
    <!-- Use your resume roles here -->
    <article class="flow-card">
      <h3>Dec 2024 – Present · Deerfield, IL</h3>
      <h4>Senior Data Scientist — Walgreens (TCS)</h4>
      <p>Databricks forecasting; ADF automation; modular Python components.</p>
      <div class="meta"><span class="pill">Python</span><span class="pill">Databricks</span><span class="pill">ADF</span></div>
    </article>
    <article class="flow-card">
      <h3>Jul 2023 – Nov 2024 · Chicago, IL</h3>
      <h4>Sr. Data Analyst & Technical Architect — UnitedHealthcare (TCS)</h4>
      <p>Governed KPIs; Tableau → Power BI; SSIS & SQL Agent orchestration.</p>
      <div class="meta"><span class="pill">Power BI</span><span class="pill">Tableau</span><span class="pill">SSIS</span></div>
    </article>
    <article class="flow-card">
      <h3>Mar 2022 – Jun 2022 · Chicago, IL</h3>
      <h4>Data Analyst & Data Governance Lead — Galderma (TCS)</h4>
      <p>Automated KPI reporting; Databricks packages; 25%+ manual reduction.</p>
      <div class="meta"><span class="pill">Governance</span><span class="pill">Power BI</span></div>
    </article>    
    <article class="flow-card">
      <h3>Jul 2022 – Jun 2023 · Chicago, IL</h3>
      <h4>Data Analytics Lead — Bombardier (TCS)</h4>
      <p>Metrics for aero ops in Databricks; Python ETL; leadership insights.</p>
      <div class="meta"><span class="pill">Pandas</span><span class="pill">Databricks</span></div>
    </article>
    <article class="flow-card">
      <h3>Oct 2017 – Feb 2022 · Deerfield, IL</h3>
      <h4>Data Analytics & EPM Lead — Walgreens (TCS)</h4>
      <p>Create dynamic Power BI dashboards; improve pipelines and reporting by 71%.</p>
      <div class="meta"><span class="pill">Python</span><span class="pill">EPM</span></div>
    </article>
    <article class="flow-card">
      <h3>Jun 2013 – Sep 2017 · Deerfield, IL</h3>
      <h4>Master Data Management (MDM) and Analytics Lead — Walgreens (TCS)</h4>
      <p>Implement data governance processes; improve accounting reports and KPIs by 62%.</p>
      <div class="meta"><span class="pill">Power BI</span><span class="pill">MDM</span></div>
    </article>
    <article class="flow-card">
      <h3>Nov 2010 – Nov 2011 · Deerfield, IL</h3>
      <h4>Data Analyst and Report Developer - Experian (TCS)</h4>
      <p>Build predictive models and KPIs; improve efficiency by 64%.</p>
      <div class="meta"><span class="pill">PL/SQL</span><span class="pill">Python</span></div>
    </article>  
    <article class="flow-card">
      <h3>Oct 2011 – May 2013 · Deerfield, IL</h3>
      <h4>Senior Data Analyst and Report Developer - Experian (TCS)</h4>
      <p>Create scalable data lakes; optimize complex pipelines by 84%.</p>
      <div class="meta"><span class="pill">Informatica</span><span class="pill">PL/SQL</span></div>
    </article>
    <article class="flow-card">
      <h3>Dec 2009 – Oct 2010 · Kolkata, India</h3>
      <h4>Oracle Database Administrator - Toyota Financial Services (TCS)</h4>
      <p>Create Virtual Private Database; resolved ~75% manual issues.</p>
      <div class="meta"><span class="pill">SQL</span><span class="pill">Unix</span></div>
    </article>      
    <!-- Add older roles as needed -->
  </div>
</section>

<style>

/* ---------- ROLES (left menu + panels) ---------- */
.role-gallery.impacts{ align-items:start }
.role-btn{ padding:.6rem .8rem; border:1px solid #dbe3f0; border-radius:.6rem; background:#fff; cursor:pointer; transition:background .15s, transform .05s }
.role-btn.active{ background:#eef5ff; border-color:#b7d2ff }
.role-btn:active{ transform: translateY(1px) }
.role-summary{ display:block; margin:.25rem 0 .5rem; color:#4b5563 }

/* Accordion */
.role-accordion{ display:grid; gap:.6rem }
.acc-item{ border:1px solid #e5e7eb; border-radius:12px; background:#fff; overflow:hidden; box-shadow:0 1px 6px rgba(0,0,0,.03) }
.acc-head{ display:block }
.acc-btn{ display:flex; flex-direction:column; align-items:flex-start; gap:.25rem; width:100%; padding:1rem; font-weight:650; color:#343a40; text-align:left; border:0; background:linear-gradient(#fafbfc,#f6f8fb) }
.acc-btn:focus{ outline:2px solid #e3ecff; outline-offset:2px }
.acc-meta{ font-size:.82rem; font-weight:400; color:#6b7280 }
.acc-panel[hidden]{ display:none }
.acc-body{ padding:.75rem 1rem 1rem }
.acc-body details{ margin:.35rem 0; border-left:3px solid #e5e7eb; padding:.25rem .75rem; background:#fafafa; border-radius:0 6px 6px 0 }
.acc-body summary{ cursor:pointer; user-select:none }
.acc-body ul{ margin:.35rem 0 .25rem 1.1rem }
.mono{ font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace }

/* ---------- EXPERIENCE FLOW ---------- */
/* Hide the visual on small screens to avoid cramping; remove if you want it visible */
@media (max-width: 900px){ .experience-flow{ display:none } }

.experience-flow{ position:relative; margin:2rem auto 2.5rem; max-width:1100px }
.flow-svg{ position:absolute; inset:0; width:100%; height:100%; pointer-events:none; z-index:0 }
.flow-grid{ position:relative; display:grid; grid-template-columns:repeat(auto-fill,minmax(280px,1fr)); gap:22px; align-items:stretch; z-index:1 }
.flow-card{ background:#fff; border:1px solid #e8eaf0; border-radius:14px; padding:16px; box-shadow:0 8px 24px rgba(20,24,62,.06); transition:transform .18s, box-shadow .18s, border-color .18s }
.flow-card:hover,.flow-card:focus-within{ transform:translateY(-2px); border-color:#d7dbe8; box-shadow:0 12px 28px rgba(20,24,62,.09) }
.flow-card h3{ margin:0 0 6px; font-size:.95rem; font-weight:700; color:#0b4dbf }
.flow-card h4{ margin:0 0 8px; font-size:1.02rem; font-weight:700; color:#1e293b }
.flow-card p{ margin:0; color:#475569; font-size:.92rem; line-height:1.4 }
.meta{ display:flex; flex-wrap:wrap; gap:6px; margin-top:10px }
.pill{ font-size:.74rem; font-weight:600; padding:4px 8px; border-radius:999px; color:#0b4dbf; background:linear-gradient(180deg,#eff6ff,#e7f3ff); border:1px solid #cfe3ff }

/* Flow stroke + nodes */
.path-stroke{ stroke:url(#flow-grad); stroke-width:3.2; stroke-linecap:round; stroke-linejoin:round; fill:none; marker-end:url(#arrow-head); animation:pathDraw 1.2s ease-out both }
@keyframes pathDraw{ from{ stroke-dasharray:1 1000; opacity:0 } to{ stroke-dasharray:1000 0; opacity:1 } }
.node{ fill:#fff; stroke:#1e88e5; stroke-width:2.2; r:4.2 }
</style>

<script>
/* ===== Role UI ===== */
const ROLE_SUMMARIES = {
  analyst: "Analyst impacts: governed KPIs, SQL modeling, high-adoption dashboards.",
  scientist: "Scientist impacts: forecasting pipelines, feature engineering, measurable lifts.",
  engineer: "Engineer impacts: medallion ELT, reliability, cost control.",
  aiml: "AI/ML impacts: streaming detection, latency & precision improvements.",
  genai: "Gen AI impacts: RAG, evaluation, and guardrail design.",
  businessanalyst: "BA impacts: discovery → metrics → enablement with stakeholder alignment."
};
const summaryEl = document.getElementById("role-summary");

function setSummary(role){
  if(!summaryEl) return;
  summaryEl.textContent = ROLE_SUMMARIES[role] || "Explore impacts by role.";
  if (window.runWordIconizer) window.runWordIconizer(summaryEl);
}

function activateRole(role){
  document.querySelectorAll(".role-btn").forEach(btn => {
    const on = btn.dataset.role === role;
    btn.classList.toggle("active", on);
    btn.setAttribute("aria-current", on ? "page" : "false");
  });
  document.querySelectorAll(".role-slideshows .role-accordion").forEach(p => p.hidden = true);
  const panel = document.getElementById(`panel-${role}`);
  if(panel){ panel.hidden = false; }
  setSummary(role);
  if (window.runWordIconizer && panel) window.runWordIconizer(panel);
}
document.querySelectorAll(".role-btn").forEach(btn => btn.addEventListener("click", ()=>activateRole(btn.dataset.role)));

/* Accordions (one open per panel) */
function wireAccordion(container){
  container.addEventListener("click", (e) => {
    const btn = e.target.closest(".acc-btn");
    if(!btn) return;
    const panelId = btn.getAttribute("aria-controls");
    const panel = document.getElementById(panelId);
    const expanded = btn.getAttribute("aria-expanded") === "true";

    container.querySelectorAll(".acc-btn[aria-expanded='true']").forEach(b => b.setAttribute("aria-expanded","false"));
    container.querySelectorAll(".acc-panel").forEach(p => p.hidden = true);

    if(!expanded){
      btn.setAttribute("aria-expanded","true");
      panel.hidden = false;
      animateKPIs(panel);
      if (window.runWordIconizer) window.runWordIconizer(panel);
    }
  });
}
document.querySelectorAll(".role-accordion").forEach(wireAccordion);

/* KPI animation */
function animateKPIs(scope){
  const counters = (scope || document).querySelectorAll('.kpi');
  counters.forEach(counter => {
    const target = +counter.getAttribute('data-target');
    let val = 0;
    const step = Math.max(1, Math.round(target / 50));
    const tick = () => {
      val += step;
      if (val < target) { counter.textContent = val; requestAnimationFrame(tick); }
      else { counter.textContent = target; }
    };
    if (!counter.dataset.animated){ counter.dataset.animated = "1"; requestAnimationFrame(tick); }
  });
}

/* Default open role */
activateRole("analyst");

/* ===== Experience Flow (arrow underlay) ===== */
(function(){
  const grid = document.getElementById('flow-grid');
  const svg  = document.getElementById('flow-svg');
  if(!grid || !svg) return;

  const debounce = (fn, ms=120)=>{ let t; return (...a)=>{ clearTimeout(t); t=setTimeout(()=>fn(...a), ms); }; };

  function drawFlow(){
    const cards = Array.from(grid.querySelectorAll('.flow-card'));
    if (!cards.length) return;

    const r = grid.getBoundingClientRect();
    const w = Math.ceil(r.width);
    const h = Math.ceil(r.height);
    svg.setAttribute('viewBox', `0 0 ${w} ${h}`);
    svg.setAttribute('width', w);
    svg.setAttribute('height', h);

    svg.innerHTML = `
      <defs>
        <linearGradient id="flow-grad" x1="0%" y1="0%" x2="100%" y2="0%">
          <stop offset="0%" stop-color="#1976d2"/><stop offset="100%" stop-color="#00bcd4"/>
        </linearGradient>
        <marker id="arrow-head" viewBox="0 0 10 10" refX="8" refY="5" markerWidth="8" markerHeight="8" orient="auto-start-reverse">
          <path d="M0,0 L10,5 L0,10 z" fill="#00bcd4"></path>
        </marker>
      </defs>
    `;

    const pts = cards.map(el=>{
      const cr = el.getBoundingClientRect();
      return { x: (cr.left - r.left) + cr.width/2, y: (cr.top - r.top) + cr.height/2 };
    });

    const rows = [];
    const rowThresh = 44;
    pts.forEach(p=>{
      let row = rows.find(rr => Math.abs(rr.y - p.y) < rowThresh);
      if (!row){ row = { y:p.y, pts:[] }; rows.push(row); }
      row.pts.push(p);
    });
    rows.sort((a,b)=>a.y-b.y);
    rows.forEach(row => row.pts.sort((a,b)=>a.x-b.x));

    let d = '';
    const nodes = [];
    rows.forEach((row, i)=>{
      const ordered = (i % 2 === 0) ? row.pts : row.pts.slice().reverse();
      ordered.forEach((p, j)=>{
        const x = Math.round(p.x), y = Math.round(p.y);
        nodes.push({x,y});
        d += (i===0 && j===0) ? `M ${x} ${y} ` : `L ${x} ${y} `;
      });
      const next = rows[i+1];
      if (next){
        const last = ordered[ordered.length-1];
        const nextFirst = ((i+1) % 2 === 0) ? next.pts[0] : next.pts.slice().reverse()[0];
        const midY = (last.y + nextFirst.y) / 2;
        d += `Q ${Math.round(last.x)} ${Math.round(midY)} ${Math.round(nextFirst.x)} ${Math.round(nextFirst.y)} `;
      }
    });

    const path = document.createElementNS('http://www.w3.org/2000/svg','path');
    path.setAttribute('class','path-stroke');
    path.setAttribute('d', d.trim());
    svg.appendChild(path);

    nodes.forEach(n=>{
      const c = document.createElementNS('http://www.w3.org/2000/svg','circle');
      c.setAttribute('class','node');
      c.setAttribute('cx', Math.round(n.x));
      c.setAttribute('cy', Math.round(n.y));
      c.setAttribute('r', 4.2);
      svg.appendChild(c);
    });
  }

  const run = debounce(drawFlow, 60);
  window.addEventListener('load', run);
  window.addEventListener('resize', run);
  new ResizeObserver(run).observe(grid);
})();
</script>
